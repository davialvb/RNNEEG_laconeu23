{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c36c6fbc",
   "metadata": {},
   "source": [
    "# EEG classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84b63a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a45a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e026afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../dataset/\"\n",
    "\n",
    "for dirname, _, filenames in os.walk(data_path):\n",
    "    for filename in filenames:\n",
    "        if \"train\" in filename:\n",
    "            train_path = os.path.join(dirname, filename)\n",
    "        if \"test\" in filename:\n",
    "            test_path = os.path.join(dirname, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536dd3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_target(target):\n",
    "    if target == -55:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6292ce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "# remove unnamed columns\n",
    "train_df = train_df.iloc[: , 3:]\n",
    "test_df = test_df.iloc[: , 3:]\n",
    "\n",
    "# change target value\n",
    "train_df.target = train_df.target.apply(encode_target)\n",
    "test_df.target = test_df.target.apply(encode_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce118603",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_df.iloc[2:3, :-1].to_numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13791eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes\n",
    "np.unique(train_df.to_numpy()[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be641c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_conf_matrix(y_true, y_pred):\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "    ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "    plt.xlabel('Predictions', fontsize=18)\n",
    "    plt.ylabel('Actuals', fontsize=18)\n",
    "    plt.title('Confusion Matrix', fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51002f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(train_df, test_df, batch_size = 100, val_split=0.3):\n",
    "    \n",
    "    # transform dataframe to numpy array\n",
    "    train_data = train_df.to_numpy()\n",
    "    test_data = test_df.to_numpy()\n",
    "    \n",
    "    # create x and y\n",
    "    x_train = train_data[:, :-1]/train_data[:, :-1].max()\n",
    "    x_test = test_data[:, :-1]/test_data[:, :-1].max()\n",
    "    y_train = train_data[:, -1]\n",
    "    y_test = test_data[:, -1]\n",
    "    \n",
    "    x_train = x_train[:, :178]\n",
    "    x_test = x_test[:, :178]\n",
    "\n",
    "    # create tensor dataset of x and y\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(x_train).float(),\n",
    "                                                   torch.from_numpy(y_train).long(),)\n",
    "    test_dataset = torch.utils.data.TensorDataset(torch.from_numpy(x_test).float(),\n",
    "                                                  torch.from_numpy(y_test).long())\n",
    "    \n",
    "    # split dataset in train, val and test\n",
    "    train_len = train_data.shape[0]\n",
    "    val_len = int(train_len * val_split)\n",
    "    train_len -= val_len\n",
    "\n",
    "    # shuffle train and validade data\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_len, val_len])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a88f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "val_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c223f8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = create_data_loader(train_df, test_df, batch_size = batch_size, val_split=val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e6925",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        \n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # RNN\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "            \n",
    "        # One time step\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efef9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10 # number of training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6244d832",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 178   # input dimension\n",
    "hidden_dim = 1000  # hidden layer dimension\n",
    "layer_dim = 1     # number of hidden layers\n",
    "output_dim = 2   # output dimension\n",
    "\n",
    "# Initiate RNN model\n",
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.05\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b8b5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_dim = 178\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "y_true=[]\n",
    "y_pred=[]\n",
    "count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (signals, labels) in enumerate(train_loader):\n",
    "\n",
    "        train = signals.unsqueeze(1)\n",
    "        labels = labels.long()\n",
    "            \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Calculate softmax and ross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        if count % (test_df.shape[0]//batch_size) == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for signals, labels in val_loader:\n",
    "                signals = signals.unsqueeze(1)\n",
    "                \n",
    "                # Forward propagation\n",
    "                outputs = model(signals)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "            y_true+=labels\n",
    "            y_pred+=predicted\n",
    "#             if count % 10 == 0:\n",
    "                # Print validade loss\n",
    "            print('iteration: {}  val_loss: {}  val_accuracy: {} %'.format(count, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc673ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "for signals, labels in test_loader:\n",
    "    signals = signals.unsqueeze(1)\n",
    "\n",
    "    # Forward propagation\n",
    "    outputs = model(signals)\n",
    "\n",
    "    # Get predictions from the maximum value\n",
    "    predicted = torch.max(outputs.data, 1)[1]\n",
    "\n",
    "    # Total number of labels\n",
    "    total += labels.size(0)\n",
    "\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "accuracy = 100 * correct / float(total)\n",
    "\n",
    "# store loss and iteration\n",
    "# loss_list.append(loss.data)\n",
    "# accuracy_list.append(accuracy)\n",
    "y_true+=labels\n",
    "y_pred+=predicted\n",
    "# Print validade loss\n",
    "print('test_accuracy: {} %'.format(accuracy.numpy().round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9de3e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_conf_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea3d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization loss \n",
    "plt.plot(iteration_list,loss_list)\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"RNN: Loss vs Number of iteration\")\n",
    "plt.show()\n",
    "\n",
    "# visualization accuracy \n",
    "plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"RNN: Accuracy vs Number of iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5617fe68",
   "metadata": {},
   "source": [
    "### Test model with an experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc12bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_loader(test_df, batch_size = 100):\n",
    "    \n",
    "    # transform dataframe to numpy array\n",
    "    test_data = test_df.to_numpy()\n",
    "    \n",
    "    # create x and y\n",
    "    x_test = test_data[:, :-1]/test_data[:, :-1].max()\n",
    "    y_test = test_data[:, -1]\n",
    "\n",
    "    # create tensor dataset of x and y\n",
    "    test_dataset = torch.utils.data.TensorDataset(torch.from_numpy(x_test).float(),\n",
    "                                                  torch.from_numpy(y_test).long())\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be05cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dataset/experimental_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd8bcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove first column\n",
    "final_test_df = df.iloc[: , 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2095a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(target):\n",
    "    if target==1:\n",
    "        return 0\n",
    "    elif target==2:\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f05e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select targets 1 and 2\n",
    "final_test_df.y = final_test_df.y.apply(get_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ac0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_df.y.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d53fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing values\n",
    "final_test_df.dropna(subset=[\"y\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c772e042",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = test_data_loader(final_test_df, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a56fd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "for signals, labels in test_loader:\n",
    "    signals = signals.unsqueeze(1)\n",
    "\n",
    "    # Forward propagation\n",
    "    outputs = model(signals)\n",
    "\n",
    "    # Get predictions from the maximum value\n",
    "    predicted = torch.max(outputs.data, 1)[1]\n",
    "\n",
    "    # Total number of labels\n",
    "    total += labels.size(0)\n",
    "\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "accuracy = 100 * correct / float(total)\n",
    "\n",
    "# store loss and iteration\n",
    "# loss_list.append(loss.data)\n",
    "# accuracy_list.append(accuracy)\n",
    "y_true+=labels\n",
    "y_pred+=predicted\n",
    "# Print validade loss\n",
    "print('test_accuracy: {} %'.format(accuracy.numpy().round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697ab286",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_conf_matrix(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
